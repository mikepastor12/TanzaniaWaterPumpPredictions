{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8854461",
   "metadata": {},
   "source": [
    "#  Tanzania Water Pump Failure Predictions - Competition\n",
    "\n",
    "## <font color=green>Implement a Predictive Model to help solve this problem and submit to DRIVENDATA competition</font>\n",
    "\n",
    "\n",
    "\n",
    ">  **This is a WORK-IN-PROGRESS -   10/26/2022 - please check back for the final version...**\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "Can you predict which water pumps are faulty?\n",
    "\n",
    "Using data from Taarifa and the Tanzanian Ministry of Water, \n",
    "can you predict which pumps are functional, which need some repairs, \n",
    "and which don't work at all? Predict one of these three classes\n",
    "based on a number of variables about what kind of pump is operating, \n",
    "when it was installed, and how it is managed. \n",
    "\n",
    "A smart understanding of which waterpoints will fail can improve maintenance operations \n",
    "and ensure that clean, potable water is available to communities across Tanzania.\n",
    "\n",
    "...\n",
    "\n",
    "Hope this simple example of an XGBoost predictive model helps!\n",
    "\n",
    "All the best,\n",
    "Mike Pastor\n",
    "\n",
    "\n",
    "**Competition Home Page:**  \n",
    "[DRIVENDATA - Data science competitions\n",
    "to build a better world](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/page/23/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b04a294",
   "metadata": {},
   "source": [
    "#  First, let's load all of the necessary Python libraries\n",
    "#    ( Note: these need to be installed on the Python instance running the NoteBook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1202cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd # load and manipulate data and for One-Hot Encoding\n",
    "import numpy as np # calculate the mean and standard deviation\n",
    "import xgboost as xgb # XGBoost stuff\n",
    "from sklearn.model_selection import train_test_split # split  data into training and testing sets\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer # for scoring during cross validation\n",
    "from sklearn.model_selection import GridSearchCV # cross validation\n",
    "from sklearn.metrics import confusion_matrix # creates a confusion matrix\n",
    "from sklearn.metrics import plot_confusion_matrix # draws a confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1a6e89",
   "metadata": {},
   "source": [
    "#  Now, let's open the Datasets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47156000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount_tsh           float64\n",
      "gps_height             int64\n",
      "longitude            float64\n",
      "latitude             float64\n",
      "population             int64\n",
      "construction_year      int64\n",
      "dtype: object\n",
      "Datasets Loaded & Merged...   Y - X  (59400, 1) (59400, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load TRAIN datasets ###########################################################\n",
    "#\n",
    "train_X = pd.read_csv('./TrainingSetValues.csv')\n",
    "train_Y = pd.read_csv('./TrainingSetLABELS.csv')\n",
    "\n",
    "# Merge the Y onto the X to be sure they are matched\n",
    "#  This adds 'status_group' LABEL onto each X example row\n",
    "#\n",
    "train_X = train_X.merge( train_Y, how='inner', on='id' )\n",
    "\n",
    "\n",
    "\n",
    "#########################################################\n",
    "# replacing Y  string values with numerics\n",
    "#    This is becomes part of our Tanzania Data Dictionary\n",
    "#\n",
    "train_X['status_group'].replace(\\\n",
    "    ['functional', 'functional needs repair', 'non functional'],\\\n",
    "    [0, 1, 2], inplace=True)\n",
    "\n",
    "# Used the synchronized - quantitative  LABEL for Y\n",
    "train_Y = pd.DataFrame( train_X['status_group'], columns=['status_group'] )\n",
    "\n",
    "\n",
    "########################################################\n",
    "#  Also  Load the TEST dataset which is used for the Submission preparation\n",
    "#\n",
    "test_X = pd.read_csv('./TestSetValues.csv')\n",
    "\n",
    "\n",
    "#  Take a subset for testing\n",
    "train_X = train_X[ [    'amount_tsh', 'gps_height', 'longitude', 'latitude', 'population', 'construction_year' ] ]\n",
    "#                         # 'latitude', 'longitude', 'basin', 'region_code', 'district_code', 'population', \\\n",
    "#                         # 'scheme_name', 'scheme_management', 'construction_year', 'quantity',   'payment', \\\n",
    "#                         # 'extraction_type', 'extraction_type_class', 'source', 'source_type', \\\n",
    "#                         'management', 'waterpoint_type'  ]  ]\n",
    "\n",
    "\n",
    "# Save IDs for Submission file preparation below\n",
    "test_X_Saved_IDs = test_X[ [  'id' ] ]\n",
    "\n",
    "test_X = test_X[ [      'amount_tsh', 'gps_height', 'longitude', 'latitude', 'population', 'construction_year' ] ]\n",
    "                        # 'latitude', 'longitude', 'basin', 'region_code', 'district_code', 'population', \\\n",
    "                        # 'scheme_name', 'scheme_management', 'construction_year', 'quantity',   'payment', \\\n",
    "                        # 'extraction_type', 'extraction_type_class', 'source', 'source_type', \\\n",
    "                        # 'management', 'waterpoint_type'  ]  ]\n",
    "\n",
    "\n",
    "print( train_X.dtypes )\n",
    "\n",
    "\n",
    "print('Datasets Loaded & Merged...   Y - X ', train_Y.shape, train_X.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcbace0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
